{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "FP KK.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "mVF-TaTSBYYm",
        "0-51CSbpB5Bz"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/josepheric/Titanic-Survivor-Prediction/blob/main/FP_KK.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pc9DjE74_n-b"
      },
      "source": [
        "# Titanic Survivor Prediction"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A-zNrWQN_wN9"
      },
      "source": [
        "## Import Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DhuB2XGqiesb"
      },
      "source": [
        "#read csv\r\n",
        "import pandas as pd\r\n",
        "\r\n",
        "url = 'https://raw.githubusercontent.com/josepheric/Titanic-Survivor-Prediction/main/train.csv'\r\n",
        "dataset = pd.read_csv(url)\r\n",
        "\r\n",
        "# Things to add:\r\n",
        "# 1.\tVisualisasi pake orange\r\n",
        "# 2.\tBalancing\r\n",
        "# 3.\tOutlier management"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 247
        },
        "id": "QCOEKK7jirVc",
        "outputId": "489e75de-c42d-45f5-cba6-1c6ea8577eed"
      },
      "source": [
        "#Check dataset sudah terbaca\r\n",
        "dataset.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>PassengerId</th>\n",
              "      <th>Survived</th>\n",
              "      <th>Pclass</th>\n",
              "      <th>Name</th>\n",
              "      <th>Sex</th>\n",
              "      <th>Age</th>\n",
              "      <th>SibSp</th>\n",
              "      <th>Parch</th>\n",
              "      <th>Ticket</th>\n",
              "      <th>Fare</th>\n",
              "      <th>Cabin</th>\n",
              "      <th>Embarked</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>Braund, Mr. Owen Harris</td>\n",
              "      <td>male</td>\n",
              "      <td>22.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>A/5 21171</td>\n",
              "      <td>7.2500</td>\n",
              "      <td>NaN</td>\n",
              "      <td>S</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
              "      <td>female</td>\n",
              "      <td>38.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>PC 17599</td>\n",
              "      <td>71.2833</td>\n",
              "      <td>C85</td>\n",
              "      <td>C</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>Heikkinen, Miss. Laina</td>\n",
              "      <td>female</td>\n",
              "      <td>26.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>STON/O2. 3101282</td>\n",
              "      <td>7.9250</td>\n",
              "      <td>NaN</td>\n",
              "      <td>S</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
              "      <td>female</td>\n",
              "      <td>35.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>113803</td>\n",
              "      <td>53.1000</td>\n",
              "      <td>C123</td>\n",
              "      <td>S</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>Allen, Mr. William Henry</td>\n",
              "      <td>male</td>\n",
              "      <td>35.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>373450</td>\n",
              "      <td>8.0500</td>\n",
              "      <td>NaN</td>\n",
              "      <td>S</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   PassengerId  Survived  Pclass  ...     Fare Cabin  Embarked\n",
              "0            1         0       3  ...   7.2500   NaN         S\n",
              "1            2         1       1  ...  71.2833   C85         C\n",
              "2            3         1       3  ...   7.9250   NaN         S\n",
              "3            4         1       1  ...  53.1000  C123         S\n",
              "4            5         0       3  ...   8.0500   NaN         S\n",
              "\n",
              "[5 rows x 12 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8FyWEoAu_6Jl"
      },
      "source": [
        "## Analisa Awal Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "au99pv2di9BW",
        "outputId": "2830d9f5-a536-46f1-cc4a-d942001e8eb3"
      },
      "source": [
        "dataset.info ()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 891 entries, 0 to 890\n",
            "Data columns (total 12 columns):\n",
            " #   Column       Non-Null Count  Dtype  \n",
            "---  ------       --------------  -----  \n",
            " 0   PassengerId  891 non-null    int64  \n",
            " 1   Survived     891 non-null    int64  \n",
            " 2   Pclass       891 non-null    int64  \n",
            " 3   Name         891 non-null    object \n",
            " 4   Sex          891 non-null    object \n",
            " 5   Age          714 non-null    float64\n",
            " 6   SibSp        891 non-null    int64  \n",
            " 7   Parch        891 non-null    int64  \n",
            " 8   Ticket       891 non-null    object \n",
            " 9   Fare         891 non-null    float64\n",
            " 10  Cabin        204 non-null    object \n",
            " 11  Embarked     889 non-null    object \n",
            "dtypes: float64(2), int64(5), object(5)\n",
            "memory usage: 83.7+ KB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 287
        },
        "id": "oq_xwtBSD5G_",
        "outputId": "ff6a742a-6331-476e-dca4-94ac1f7ff496"
      },
      "source": [
        "dataset.describe()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>PassengerId</th>\n",
              "      <th>Survived</th>\n",
              "      <th>Pclass</th>\n",
              "      <th>Age</th>\n",
              "      <th>SibSp</th>\n",
              "      <th>Parch</th>\n",
              "      <th>Fare</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>891.000000</td>\n",
              "      <td>891.000000</td>\n",
              "      <td>891.000000</td>\n",
              "      <td>714.000000</td>\n",
              "      <td>891.000000</td>\n",
              "      <td>891.000000</td>\n",
              "      <td>891.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>446.000000</td>\n",
              "      <td>0.383838</td>\n",
              "      <td>2.308642</td>\n",
              "      <td>29.699118</td>\n",
              "      <td>0.523008</td>\n",
              "      <td>0.381594</td>\n",
              "      <td>32.204208</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>257.353842</td>\n",
              "      <td>0.486592</td>\n",
              "      <td>0.836071</td>\n",
              "      <td>14.526497</td>\n",
              "      <td>1.102743</td>\n",
              "      <td>0.806057</td>\n",
              "      <td>49.693429</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.420000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>223.500000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>20.125000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>7.910400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>446.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>28.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>14.454200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>668.500000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>38.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>31.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>891.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>80.000000</td>\n",
              "      <td>8.000000</td>\n",
              "      <td>6.000000</td>\n",
              "      <td>512.329200</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       PassengerId    Survived      Pclass  ...       SibSp       Parch        Fare\n",
              "count   891.000000  891.000000  891.000000  ...  891.000000  891.000000  891.000000\n",
              "mean    446.000000    0.383838    2.308642  ...    0.523008    0.381594   32.204208\n",
              "std     257.353842    0.486592    0.836071  ...    1.102743    0.806057   49.693429\n",
              "min       1.000000    0.000000    1.000000  ...    0.000000    0.000000    0.000000\n",
              "25%     223.500000    0.000000    2.000000  ...    0.000000    0.000000    7.910400\n",
              "50%     446.000000    0.000000    3.000000  ...    0.000000    0.000000   14.454200\n",
              "75%     668.500000    1.000000    3.000000  ...    1.000000    0.000000   31.000000\n",
              "max     891.000000    1.000000    3.000000  ...    8.000000    6.000000  512.329200\n",
              "\n",
              "[8 rows x 7 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KXPcbm7AXDGx",
        "outputId": "dee1fd7a-bf9b-47be-ff7a-a9557790a1ea"
      },
      "source": [
        "dataset[\"Survived\"].value_counts()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    549\n",
              "1    342\n",
              "Name: Survived, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qgNpdhVqjO9E",
        "outputId": "a1ab8366-d49a-4424-f14a-a177823667f1"
      },
      "source": [
        "#Itung values dari tiap attribut\r\n",
        "dataset[\"Sex\"].value_counts()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "male      577\n",
              "female    314\n",
              "Name: Sex, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BAfr0f36j9BZ",
        "outputId": "bd217a2c-fd47-4f9c-ad79-5c947c5a6618"
      },
      "source": [
        "dataset[\"Pclass\"].value_counts()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3    491\n",
              "1    216\n",
              "2    184\n",
              "Name: Pclass, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MwH1GV9fj9eB",
        "outputId": "89212c07-c9d6-40d2-e7db-0e71f4074d3c"
      },
      "source": [
        "dataset[\"Embarked\"].value_counts()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "S    644\n",
              "C    168\n",
              "Q     77\n",
              "Name: Embarked, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "41AEpJlbj9pF",
        "outputId": "5963e2e5-5926-4808-eea4-a99faa78be85"
      },
      "source": [
        "dataset[\"Ticket\"].value_counts()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "CA. 2343        7\n",
              "1601            7\n",
              "347082          7\n",
              "347088          6\n",
              "3101295         6\n",
              "               ..\n",
              "350035          1\n",
              "28425           1\n",
              "F.C.C. 13528    1\n",
              "330932          1\n",
              "374746          1\n",
              "Name: Ticket, Length: 681, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yn00uhrdj9vy",
        "outputId": "d6a14ac7-2073-4d72-8a97-dbf784126f5f"
      },
      "source": [
        "dataset[\"SibSp\"].value_counts()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    608\n",
              "1    209\n",
              "2     28\n",
              "4     18\n",
              "3     16\n",
              "8      7\n",
              "5      5\n",
              "Name: SibSp, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-mFd5CBOkIhD",
        "outputId": "4dcc3e68-4071-428b-8e97-8cf32e757445"
      },
      "source": [
        "dataset[\"Parch\"].value_counts()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    678\n",
              "1    118\n",
              "2     80\n",
              "5      5\n",
              "3      5\n",
              "4      4\n",
              "6      1\n",
              "Name: Parch, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RrHgge-WkPW6"
      },
      "source": [
        "Hasil Analisis Awal: \r\n",
        "*  Ada 3 Categorical Features\r\n",
        "*  Attribut Age, Cabin, dan Embarked punya null values\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 717
        },
        "id": "Nj_8andDkwV7",
        "outputId": "abf9ad4d-045a-4609-c5c8-659ecdef4f28"
      },
      "source": [
        "%matplotlib inline \r\n",
        "import matplotlib.pyplot as plt\r\n",
        "dataset.hist(bins=50, figsize=(20,15))\r\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1440x1080 with 9 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cgriL3WPk1pV",
        "outputId": "a54acc7b-02c4-4a92-ad1c-cd2eae235828"
      },
      "source": [
        "corr_matrix = dataset.corr()\r\n",
        "corr_matrix[\"Survived\"].sort_values(ascending=False)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Survived       1.000000\n",
              "Fare           0.257307\n",
              "Parch          0.081629\n",
              "PassengerId   -0.005007\n",
              "SibSp         -0.035322\n",
              "Age           -0.077221\n",
              "Pclass        -0.338481\n",
              "Name: Survived, dtype: float64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kzphWBF5k7ZX"
      },
      "source": [
        "Correlation Analysis: \r\n",
        "1.   Passanger ID clearly not a thing -> remove \r\n",
        "2.   List itPclass korelasi negatif Fare korelasi positifem\r\n",
        "\r\n",
        "\r\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tyW0beXAAHyO"
      },
      "source": [
        "## Features Engineering"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HYDgzWsfYtEd"
      },
      "source": [
        "import string\r\n",
        "def substrings_in_string(big_string, substrings):\r\n",
        "    for substring in substrings:\r\n",
        "        try:\r\n",
        "          if big_string.find(substring) != -1:\r\n",
        "            return substring\r\n",
        "        except AttributeError:\r\n",
        "          return None  # or some other value\r\n",
        "        \r\n",
        "    \r\n",
        "    return np.nan"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JUweANssZNnm"
      },
      "source": [
        "# Features Engineering\r\n",
        "\r\n",
        "title_list=['Mrs', 'Mr', 'Master', 'Miss', 'Major', 'Rev',\r\n",
        "                    'Dr', 'Ms', 'Mlle','Col', 'Capt', 'Mme', 'Countess',\r\n",
        "                    'Don', 'Jonkheer']\r\n",
        "\r\n",
        "dataset['Title'] = dataset['Name'].map(lambda x: substrings_in_string(x, title_list))\r\n",
        "\r\n",
        "#replacing all titles with mr, mrs, miss, master\r\n",
        "def replace_titles(x):\r\n",
        "    title=x['Title']\r\n",
        "    if title in ['Don', 'Major', 'Capt', 'Jonkheer', 'Rev', 'Col']:\r\n",
        "        return 'Mr'\r\n",
        "    elif title in ['Countess', 'Mme']:\r\n",
        "        return 'Mrs'\r\n",
        "    elif title in ['Mlle', 'Ms']:\r\n",
        "        return 'Miss'\r\n",
        "    elif title =='Dr':\r\n",
        "        if x['Sex']=='Male':\r\n",
        "            return 'Mr'\r\n",
        "        else:\r\n",
        "            return 'Mrs'\r\n",
        "    else:\r\n",
        "        return title\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8EqGaTylbNdn",
        "outputId": "a247958c-f119-488c-c241-6e8c19ccd699"
      },
      "source": [
        "dataset['Cabin'].astype(str)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0       nan\n",
              "1       C85\n",
              "2       nan\n",
              "3      C123\n",
              "4       nan\n",
              "       ... \n",
              "886     nan\n",
              "887     B42\n",
              "888     nan\n",
              "889    C148\n",
              "890     nan\n",
              "Name: Cabin, Length: 891, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yOSL2zI1lIy-"
      },
      "source": [
        "# Family Size: size of a person's family\r\n",
        "dataset[\"family\"] = dataset[\"Parch\"]+ dataset[\"SibSp\"]\r\n",
        "\r\n",
        "# Price for each person\r\n",
        "dataset [\"Fare/Person\"] = dataset[\"Fare\"] / (dataset[\"family\"]+1) \r\n",
        "\r\n",
        "# Turning cabin number into Deck\r\n",
        "cabin_list = ['A', 'B', 'C', 'D', 'E', 'F', 'T', 'G', 'Unknown']\r\n",
        "dataset['Deck'] = dataset['Cabin'].map(lambda x: substrings_in_string(x, cabin_list))\r\n",
        "\r\n",
        "# Age * Class \r\n",
        "dataset['Age*Class'] = dataset['Age'] * dataset['Pclass']\r\n",
        "\r\n",
        "# Title\r\n",
        "dataset['Title'] = dataset.apply(replace_titles, axis=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CVO3K1YCgtyc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cd30c9ef-36f1-4098-b416-e81f12b60884"
      },
      "source": [
        "dataset['Deck'].value_counts()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "C    59\n",
              "B    47\n",
              "D    33\n",
              "E    33\n",
              "A    15\n",
              "F    12\n",
              "G     4\n",
              "T     1\n",
              "Name: Deck, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "II8PpPV4YYvB",
        "outputId": "95d25643-2956-4387-cf9f-b000f1cebe08"
      },
      "source": [
        "corr_matrix = dataset.corr()\r\n",
        "corr_matrix[\"Survived\"].sort_values(ascending=False)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Survived       1.000000\n",
              "Fare           0.257307\n",
              "Fare/Person    0.221600\n",
              "Parch          0.081629\n",
              "family         0.016639\n",
              "PassengerId   -0.005007\n",
              "SibSp         -0.035322\n",
              "Age           -0.077221\n",
              "Pclass        -0.338481\n",
              "Age*Class     -0.338900\n",
              "Name: Survived, dtype: float64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O3p7WFD-12lg"
      },
      "source": [
        "## Preprocessing Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qMnOT1wVZMKG",
        "outputId": "47756609-a1e9-4a19-b484-24ee45835815"
      },
      "source": [
        "# Cleaning Data\r\n",
        "\r\n",
        "# SimpleImputer -> fill null with median\r\n",
        "from sklearn.impute import SimpleImputer\r\n",
        "imputer = SimpleImputer(strategy=\"median\")\r\n",
        "\r\n",
        "#median only on numerican attr. ; drop other attr.\r\n",
        "titanic_num = dataset[[\"Age\", \"SibSp\", \"Parch\", \"Fare\", \"Fare/Person\", \"family\", \"Age*Class\"]]\r\n",
        "\r\n",
        "#fit will estimate the median from housing_dum dataset\r\n",
        "imputer.fit(titanic_num)\r\n",
        "\r\n",
        "#median of each attr. is stored here:\r\n",
        "imputer.statistics_"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([28.    ,  0.    ,  0.    , 14.4542,  8.3   ,  0.    , 58.    ])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6_eWoDucZucu",
        "outputId": "f9642f92-f648-4f9a-e02d-d2a95ddfecdf"
      },
      "source": [
        "# Categorical Attr\r\n",
        "\r\n",
        "titanic_cat = dataset[[\"Sex\",\"Embarked\",\"Pclass\",\"Title\", \"Deck\"]]\r\n",
        "dataset[\"Embarked\"].fillna(\"S\", inplace=True)\r\n",
        "dataset[\"Deck\"].fillna(\"n/a\", inplace=True)\r\n",
        "\r\n",
        "dataset.info()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 891 entries, 0 to 890\n",
            "Data columns (total 17 columns):\n",
            " #   Column       Non-Null Count  Dtype  \n",
            "---  ------       --------------  -----  \n",
            " 0   PassengerId  891 non-null    int64  \n",
            " 1   Survived     891 non-null    int64  \n",
            " 2   Pclass       891 non-null    int64  \n",
            " 3   Name         891 non-null    object \n",
            " 4   Sex          891 non-null    object \n",
            " 5   Age          714 non-null    float64\n",
            " 6   SibSp        891 non-null    int64  \n",
            " 7   Parch        891 non-null    int64  \n",
            " 8   Ticket       891 non-null    object \n",
            " 9   Fare         891 non-null    float64\n",
            " 10  Cabin        204 non-null    object \n",
            " 11  Embarked     891 non-null    object \n",
            " 12  Title        891 non-null    object \n",
            " 13  family       891 non-null    int64  \n",
            " 14  Fare/Person  891 non-null    float64\n",
            " 15  Deck         891 non-null    object \n",
            " 16  Age*Class    714 non-null    float64\n",
            "dtypes: float64(4), int64(6), object(7)\n",
            "memory usage: 118.5+ KB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4ak0ZDcDZv-k"
      },
      "source": [
        "from sklearn.pipeline import Pipeline\r\n",
        "from sklearn.preprocessing import StandardScaler\r\n",
        "\r\n",
        "#This is our numerical column pipeline\r\n",
        "num_pipeline = Pipeline([\r\n",
        "    ('imputer', SimpleImputer(strategy=\"median\")),\r\n",
        "    ('std_scaler', StandardScaler())\r\n",
        "])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uIcGrSNPuRFK"
      },
      "source": [
        "# Split Dataset\r\n",
        "\r\n",
        "from sklearn.model_selection import train_test_split\r\n",
        "train_set, test_set = train_test_split(dataset, test_size=0.2, random_state=42)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bZZ2GRyCadrH"
      },
      "source": [
        "# Fresh Set\r\n",
        "titanic_train = dataset.drop(\"Survived\", axis=1)\r\n",
        "titanic_train_labels = dataset[\"Survived\"].copy()\r\n",
        "\r\n",
        "# Fresh Set\r\n",
        "titanic_test = dataset.drop(\"Survived\", axis=1)\r\n",
        "titanic_test_labels = dataset[\"Survived\"].copy()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vsnv3HB2adkY"
      },
      "source": [
        "# OneHotEncode\r\n",
        "# Encoded to: 001, 010, 100, etc\r\n",
        "from sklearn.preprocessing import OneHotEncoder\r\n",
        "\r\n",
        "#Column Transformer: handle categorical and numerical columns toggether\r\n",
        "from sklearn.compose import ColumnTransformer\r\n",
        "num_attribs = list(titanic_num)\r\n",
        "cat_attribs = list(titanic_cat)\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "full_pipeline = ColumnTransformer([\r\n",
        "    (\"num\", num_pipeline, num_attribs),\r\n",
        "    (\"cat\", OneHotEncoder(), cat_attribs), #This is our categorical column!\r\n",
        "])\r\n",
        "\r\n",
        "titanic_prepared = full_pipeline.fit_transform(titanic_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HDTw_Wve5iaV",
        "outputId": "473b7662-c4e4-41a2-b37e-3a4dfeef3ac9"
      },
      "source": [
        "titanic_prepared.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(891, 28)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mVF-TaTSBYYm"
      },
      "source": [
        "## Trying multiple models (Model Kasar Dengan Paramaeter Default)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dC2lSzCvB8G4",
        "outputId": "35957625-dc7b-49e8-90c6-34bd84bc291c"
      },
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\r\n",
        "from sklearn.model_selection import cross_val_score\r\n",
        "\r\n",
        "forest_clf = RandomForestClassifier(random_state=42)\r\n",
        "forest_scores = cross_val_score(forest_clf, titanic_prepared, titanic_train_labels, cv=10, scoring = 'accuracy')\r\n",
        "forest_scores.mean()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8171285892634208"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q0krfNsyCnk1",
        "outputId": "e32de47d-c998-44f1-8a87-6cdbb840a94a"
      },
      "source": [
        "from sklearn.linear_model import SGDClassifier\r\n",
        "\r\n",
        "sgd_clf = SGDClassifier(random_state=42)\r\n",
        "scores = cross_val_score(sgd_clf, titanic_prepared, titanic_train_labels, cv=10, scoring = 'accuracy')\r\n",
        "scores.mean()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.7946192259675404"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jvTrIy8hDZYu",
        "outputId": "fbc7a65b-e681-430d-f1bc-e19af866968a"
      },
      "source": [
        "from sklearn.svm import LinearSVC\r\n",
        "\r\n",
        "LinSVC_clf = LinearSVC(random_state=42)\r\n",
        "scores = cross_val_score(LinSVC_clf, titanic_prepared, titanic_train_labels, cv=10, scoring = 'accuracy')\r\n",
        "scores.mean()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  \"the number of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  \"the number of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  \"the number of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  \"the number of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  \"the number of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  \"the number of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  \"the number of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  \"the number of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  \"the number of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  \"the number of iterations.\", ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8294382022471909"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xLhoHDYPGtC6",
        "outputId": "aadbd4da-0d33-4a1d-d54c-e5170c69f67d"
      },
      "source": [
        "from sklearn.svm import SVC\r\n",
        "poly_kernel_svc_clf = SVC(kernel=\"poly\", degree=2)\r\n",
        "scores = cross_val_score(poly_kernel_svc_clf, titanic_prepared, titanic_train_labels, cv=10, scoring = 'accuracy')\r\n",
        "scores.mean()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8305243445692885"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CeQXAkZrHa7Y",
        "outputId": "66f8ebd2-49de-4115-bcc4-578681b1a009"
      },
      "source": [
        "rbf_kernel_svc_clf = SVC(kernel=\"rbf\")\r\n",
        "scores = cross_val_score(rbf_kernel_svc_clf, titanic_prepared, titanic_train_labels, cv=10, scoring = 'accuracy')\r\n",
        "scores.mean()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8339076154806492"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a9Bc8cyvVtVF",
        "outputId": "49e7fa92-8a52-4d81-8e60-3669150dbbbd"
      },
      "source": [
        "titanic_prepared.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(891, 28)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uXqvIFtJsvOc"
      },
      "source": [
        "## Buat DataFrame Hasil"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vmRAN91ZtHMT"
      },
      "source": [
        "import numpy as np\r\n",
        "from sklearn.metrics import make_scorer, accuracy_score, precision_score, recall_score, f1_score\r\n",
        "def get_metrics(titanic_test_labels, y_pred):\r\n",
        "    acc=np.round(accuracy_score(titanic_test_labels, y_pred),4)\r\n",
        "    prec=np.round(precision_score(titanic_test_labels, y_pred,average='weighted'),4)\r\n",
        "    recall=np.round(recall_score(titanic_test_labels, y_pred,average='weighted'),4)\r\n",
        "    f1=np.round(f1_score(titanic_test_labels, y_pred,average='weighted'),4)\r\n",
        "    return [acc,prec,recall,f1]\r\n",
        "col=['Model','Accuracy','Precision','Recall','F1']\r\n",
        "Result=pd.DataFrame(columns=col)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1HUw944P_1z6"
      },
      "source": [
        "## SGDClassifier"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M4-EKvs0adQ2",
        "outputId": "11f5b8e3-aee7-4a7a-8316-9ceb1524b790"
      },
      "source": [
        "from sklearn.model_selection import GridSearchCV\r\n",
        "#Model\r\n",
        "from sklearn.linear_model import SGDClassifier\r\n",
        "\r\n",
        "#GridSearch = coba semua kombinasi hpyerparameters\r\n",
        "param_grid = [\r\n",
        "    {'alpha': [0.0001, 0.001, 0.005], 'loss': [\"hinge\", \"log\"], \r\n",
        "    'penalty': [\"l2\",\"l1\",\"elasticnet\"]\r\n",
        "    }]\r\n",
        "\r\n",
        "sgd_clf = SGDClassifier(random_state=42)\r\n",
        "\r\n",
        "grid_search = GridSearchCV(sgd_clf, param_grid, cv=5, scoring = 'accuracy',\r\n",
        "                           return_train_score=True)\r\n",
        "\r\n",
        "grid_search.fit(titanic_prepared, titanic_train_labels)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GridSearchCV(cv=5, error_score=nan,\n",
              "             estimator=SGDClassifier(alpha=0.0001, average=False,\n",
              "                                     class_weight=None, early_stopping=False,\n",
              "                                     epsilon=0.1, eta0=0.0, fit_intercept=True,\n",
              "                                     l1_ratio=0.15, learning_rate='optimal',\n",
              "                                     loss='hinge', max_iter=1000,\n",
              "                                     n_iter_no_change=5, n_jobs=None,\n",
              "                                     penalty='l2', power_t=0.5, random_state=42,\n",
              "                                     shuffle=True, tol=0.001,\n",
              "                                     validation_fraction=0.1, verbose=0,\n",
              "                                     warm_start=False),\n",
              "             iid='deprecated', n_jobs=None,\n",
              "             param_grid=[{'alpha': [0.0001, 0.001, 0.005],\n",
              "                          'loss': ['hinge', 'log'],\n",
              "                          'penalty': ['l2', 'l1', 'elasticnet']}],\n",
              "             pre_dispatch='2*n_jobs', refit=True, return_train_score=True,\n",
              "             scoring='accuracy', verbose=0)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Diwj8WC2axMI",
        "outputId": "92ababe5-b66f-4350-fdff-f06cc8cd8fa5"
      },
      "source": [
        "grid_search.best_score_"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8249450756386919"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 587
        },
        "id": "Mh_Bfg8R8FVm",
        "outputId": "19f3aca3-49f1-420f-da05-4c9975374e9b"
      },
      "source": [
        "pd.concat([pd.DataFrame(grid_search.cv_results_[\"params\"]),pd.DataFrame(grid_search.cv_results_[\"mean_test_score\"], columns=[\"Accuracy\"])],axis=1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>alpha</th>\n",
              "      <th>loss</th>\n",
              "      <th>penalty</th>\n",
              "      <th>Accuracy</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.0001</td>\n",
              "      <td>hinge</td>\n",
              "      <td>l2</td>\n",
              "      <td>0.776637</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.0001</td>\n",
              "      <td>hinge</td>\n",
              "      <td>l1</td>\n",
              "      <td>0.769914</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.0001</td>\n",
              "      <td>hinge</td>\n",
              "      <td>elasticnet</td>\n",
              "      <td>0.775519</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.0001</td>\n",
              "      <td>log</td>\n",
              "      <td>l2</td>\n",
              "      <td>0.772136</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.0001</td>\n",
              "      <td>log</td>\n",
              "      <td>l1</td>\n",
              "      <td>0.780033</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>0.0001</td>\n",
              "      <td>log</td>\n",
              "      <td>elasticnet</td>\n",
              "      <td>0.775551</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>0.0010</td>\n",
              "      <td>hinge</td>\n",
              "      <td>l2</td>\n",
              "      <td>0.805831</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>0.0010</td>\n",
              "      <td>hinge</td>\n",
              "      <td>l1</td>\n",
              "      <td>0.810332</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>0.0010</td>\n",
              "      <td>hinge</td>\n",
              "      <td>elasticnet</td>\n",
              "      <td>0.810345</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>0.0010</td>\n",
              "      <td>log</td>\n",
              "      <td>l2</td>\n",
              "      <td>0.824945</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>0.0010</td>\n",
              "      <td>log</td>\n",
              "      <td>l1</td>\n",
              "      <td>0.823809</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>0.0010</td>\n",
              "      <td>log</td>\n",
              "      <td>elasticnet</td>\n",
              "      <td>0.821581</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>0.0050</td>\n",
              "      <td>hinge</td>\n",
              "      <td>l2</td>\n",
              "      <td>0.823771</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>0.0050</td>\n",
              "      <td>hinge</td>\n",
              "      <td>l1</td>\n",
              "      <td>0.823765</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>0.0050</td>\n",
              "      <td>hinge</td>\n",
              "      <td>elasticnet</td>\n",
              "      <td>0.822654</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>0.0050</td>\n",
              "      <td>log</td>\n",
              "      <td>l2</td>\n",
              "      <td>0.820400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>0.0050</td>\n",
              "      <td>log</td>\n",
              "      <td>l1</td>\n",
              "      <td>0.821537</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>0.0050</td>\n",
              "      <td>log</td>\n",
              "      <td>elasticnet</td>\n",
              "      <td>0.819271</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     alpha   loss     penalty  Accuracy\n",
              "0   0.0001  hinge          l2  0.776637\n",
              "1   0.0001  hinge          l1  0.769914\n",
              "2   0.0001  hinge  elasticnet  0.775519\n",
              "3   0.0001    log          l2  0.772136\n",
              "4   0.0001    log          l1  0.780033\n",
              "5   0.0001    log  elasticnet  0.775551\n",
              "6   0.0010  hinge          l2  0.805831\n",
              "7   0.0010  hinge          l1  0.810332\n",
              "8   0.0010  hinge  elasticnet  0.810345\n",
              "9   0.0010    log          l2  0.824945\n",
              "10  0.0010    log          l1  0.823809\n",
              "11  0.0010    log  elasticnet  0.821581\n",
              "12  0.0050  hinge          l2  0.823771\n",
              "13  0.0050  hinge          l1  0.823765\n",
              "14  0.0050  hinge  elasticnet  0.822654\n",
              "15  0.0050    log          l2  0.820400\n",
              "16  0.0050    log          l1  0.821537\n",
              "17  0.0050    log  elasticnet  0.819271"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rcm5kJm9axph",
        "outputId": "91b3fb8b-007b-4a5c-915d-03ec92b7ada6"
      },
      "source": [
        "# Transform Test Set\r\n",
        "test = full_pipeline.fit_transform(titanic_test)\r\n",
        "\r\n",
        "from sklearn.metrics import accuracy_score\r\n",
        "y_pred = grid_search.predict(test)\r\n",
        "accuracy_score(titanic_test_labels, y_pred)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8181818181818182"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9K_qwjyatQ5r",
        "outputId": "f8bec306-6a6d-4de8-f5e9-e156a228e7bd"
      },
      "source": [
        "get_metrics(titanic_test_labels,y_pred)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.8182, 0.8208, 0.8182, 0.8191]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "teOCwFzTtRBm"
      },
      "source": [
        "res=['SGD']+get_metrics(titanic_test_labels,y_pred)\r\n",
        "Result=pd.concat([Result,pd.DataFrame([res],columns=col)])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0-51CSbpB5Bz"
      },
      "source": [
        "## Random Forest Classifier"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fPy4hPi1B3Zw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "016f8a88-a709-401d-8cdf-8692aca32147"
      },
      "source": [
        "#GridSearch = coba semua kombinasi hpyerparameters\r\n",
        "param_grid = [\r\n",
        "    {'n_estimators': [10, 100, 1000], \r\n",
        "     'criterion': [\"gini\", \"entropy\"]\r\n",
        "    }]\r\n",
        "\r\n",
        "RF_clf = RandomForestClassifier(random_state=42)\r\n",
        "\r\n",
        "grid_search_RF = GridSearchCV(RF_clf, param_grid, cv=5, scoring = 'accuracy',\r\n",
        "                           return_train_score=True)\r\n",
        "\r\n",
        "grid_search_RF.fit(titanic_prepared, titanic_train_labels) "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GridSearchCV(cv=5, error_score=nan,\n",
              "             estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0,\n",
              "                                              class_weight=None,\n",
              "                                              criterion='gini', max_depth=None,\n",
              "                                              max_features='auto',\n",
              "                                              max_leaf_nodes=None,\n",
              "                                              max_samples=None,\n",
              "                                              min_impurity_decrease=0.0,\n",
              "                                              min_impurity_split=None,\n",
              "                                              min_samples_leaf=1,\n",
              "                                              min_samples_split=2,\n",
              "                                              min_weight_fraction_leaf=0.0,\n",
              "                                              n_estimators=100, n_jobs=None,\n",
              "                                              oob_score=False, random_state=42,\n",
              "                                              verbose=0, warm_start=False),\n",
              "             iid='deprecated', n_jobs=None,\n",
              "             param_grid=[{'criterion': ['gini', 'entropy'],\n",
              "                          'n_estimators': [10, 100, 1000]}],\n",
              "             pre_dispatch='2*n_jobs', refit=True, return_train_score=True,\n",
              "             scoring='accuracy', verbose=0)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eHW_UK1bFxej",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b03bc227-7cbe-49ca-a58c-69e1b9989a24"
      },
      "source": [
        "print(grid_search_RF.best_score_)\r\n",
        "y_pred = grid_search_RF.predict(test)\r\n",
        "accuracy_score(titanic_test_labels, y_pred)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.8215617349821104\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9741863075196409"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YoQ-4lIW_SUr",
        "outputId": "5b94ac1f-0cba-4e4e-9170-8d481484c5e3"
      },
      "source": [
        "pd.concat([pd.DataFrame(grid_search_RF.cv_results_[\"params\"]),pd.DataFrame(grid_search_RF.cv_results_[\"mean_test_score\"], columns=[\"Accuracy\"])],axis=1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>criterion</th>\n",
              "      <th>n_estimators</th>\n",
              "      <th>Accuracy</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>gini</td>\n",
              "      <td>10</td>\n",
              "      <td>0.821562</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>gini</td>\n",
              "      <td>100</td>\n",
              "      <td>0.815950</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>gini</td>\n",
              "      <td>1000</td>\n",
              "      <td>0.810332</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>entropy</td>\n",
              "      <td>10</td>\n",
              "      <td>0.801331</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>entropy</td>\n",
              "      <td>100</td>\n",
              "      <td>0.810351</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>entropy</td>\n",
              "      <td>1000</td>\n",
              "      <td>0.815944</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  criterion  n_estimators  Accuracy\n",
              "0      gini            10  0.821562\n",
              "1      gini           100  0.815950\n",
              "2      gini          1000  0.810332\n",
              "3   entropy            10  0.801331\n",
              "4   entropy           100  0.810351\n",
              "5   entropy          1000  0.815944"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5nW_Hvy7tTgJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a0ffdeff-6369-40c3-d05c-ed944145118d"
      },
      "source": [
        "get_metrics(titanic_test_labels,y_pred)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.9742, 0.9742, 0.9742, 0.9741]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-lKx64CEtTjY"
      },
      "source": [
        "res=['RF']+get_metrics(titanic_test_labels,y_pred)\r\n",
        "Result=pd.concat([Result,pd.DataFrame([res],columns=col)])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jJxrAY9uIGGj"
      },
      "source": [
        "## SVM (linear & RBF Kernel)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sMXmmbpyINf2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c5153d55-e038-4b79-ff4f-e46afafaf0a5"
      },
      "source": [
        "#GridSearch = coba semua kombinasi hpyerparameters\r\n",
        "param_grid = [\r\n",
        "    {'C': [1, 5, 10], \r\n",
        "     'kernel': [\"rbf\", \"linear\"]\r\n",
        "    }]\r\n",
        "\r\n",
        "svm_clf = SVC(random_state=42)\r\n",
        "\r\n",
        "grid_search_svm = GridSearchCV(svm_clf, param_grid, cv=5, scoring = 'accuracy', \r\n",
        "return_train_score=True)\r\n",
        "\r\n",
        "grid_search_svm.fit(titanic_prepared, titanic_train_labels)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GridSearchCV(cv=5, error_score=nan,\n",
              "             estimator=SVC(C=1.0, break_ties=False, cache_size=200,\n",
              "                           class_weight=None, coef0=0.0,\n",
              "                           decision_function_shape='ovr', degree=3,\n",
              "                           gamma='scale', kernel='rbf', max_iter=-1,\n",
              "                           probability=False, random_state=42, shrinking=True,\n",
              "                           tol=0.001, verbose=False),\n",
              "             iid='deprecated', n_jobs=None,\n",
              "             param_grid=[{'C': [1, 5, 10], 'kernel': ['rbf', 'linear']}],\n",
              "             pre_dispatch='2*n_jobs', refit=True, return_train_score=True,\n",
              "             scoring='accuracy', verbose=0)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z-pQySVUKg5y",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b2c56a9c-1bfc-4780-dd28-4db518efeb88"
      },
      "source": [
        "print(grid_search_svm.best_score_)\r\n",
        "y_pred = grid_search_svm.predict(test)\r\n",
        "accuracy_score(titanic_test_labels, y_pred)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.8293892411022534\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8473625140291807"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 227
        },
        "id": "3s554fiU_weF",
        "outputId": "b6f78ecf-6baa-4284-ad59-a65fd64d226f"
      },
      "source": [
        "pd.concat([pd.DataFrame(grid_search_svm.cv_results_[\"params\"]),pd.DataFrame(grid_search_svm.cv_results_[\"mean_test_score\"], columns=[\"Accuracy\"])],axis=1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>C</th>\n",
              "      <th>kernel</th>\n",
              "      <th>Accuracy</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>rbf</td>\n",
              "      <td>0.829389</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>linear</td>\n",
              "      <td>0.817049</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>5</td>\n",
              "      <td>rbf</td>\n",
              "      <td>0.826050</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>5</td>\n",
              "      <td>linear</td>\n",
              "      <td>0.817042</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>10</td>\n",
              "      <td>rbf</td>\n",
              "      <td>0.808104</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>10</td>\n",
              "      <td>linear</td>\n",
              "      <td>0.817042</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    C  kernel  Accuracy\n",
              "0   1     rbf  0.829389\n",
              "1   1  linear  0.817049\n",
              "2   5     rbf  0.826050\n",
              "3   5  linear  0.817042\n",
              "4  10     rbf  0.808104\n",
              "5  10  linear  0.817042"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mHJOg8BQtXUC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "26f25ddc-daaa-45c5-9d86-58f9d9f94783"
      },
      "source": [
        "get_metrics(titanic_test_labels,y_pred)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.8474, 0.8471, 0.8474, 0.8452]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j0fsCCpPtXW6"
      },
      "source": [
        "res=['SVM']+get_metrics(titanic_test_labels,y_pred)\r\n",
        "Result=pd.concat([Result,pd.DataFrame([res],columns=col)])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IsTQJDjn_DHx"
      },
      "source": [
        "## Deep Neural Network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eY-dD2W2WO-r",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "07a78dee-2ca4-49b1-92fb-933fe8d8b5bb"
      },
      "source": [
        "import tensorflow as tf\r\n",
        "from tensorflow import keras\r\n",
        "\r\n",
        "model = keras.models.Sequential([\r\n",
        "keras.layers.Dense(28, activation=\"relu\"),\r\n",
        "keras.layers.Dense(64, activation=\"relu\"),\r\n",
        "keras.layers.Dense(300, activation=\"relu\"),\r\n",
        "keras.layers.Dense(100, activation=\"relu\"),\r\n",
        "keras.layers.Dense(1, activation=\"sigmoid\")\r\n",
        "])\r\n",
        "\r\n",
        "model.compile(loss=\"binary_crossentropy\",\r\n",
        "optimizer=\"adam\",\r\n",
        "metrics=[\"accuracy\"])\r\n",
        "\r\n",
        "model.fit(titanic_prepared, titanic_train_labels, epochs=100)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "28/28 [==============================] - 1s 2ms/step - loss: 0.6142 - accuracy: 0.6232\n",
            "Epoch 2/100\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.4865 - accuracy: 0.7796\n",
            "Epoch 3/100\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.4187 - accuracy: 0.8334\n",
            "Epoch 4/100\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.4158 - accuracy: 0.8165\n",
            "Epoch 5/100\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.3993 - accuracy: 0.8337\n",
            "Epoch 6/100\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.3852 - accuracy: 0.8431\n",
            "Epoch 7/100\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.3329 - accuracy: 0.8724\n",
            "Epoch 8/100\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.3289 - accuracy: 0.8665\n",
            "Epoch 9/100\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.3564 - accuracy: 0.8558\n",
            "Epoch 10/100\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.3256 - accuracy: 0.8639\n",
            "Epoch 11/100\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.3306 - accuracy: 0.8704\n",
            "Epoch 12/100\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.3345 - accuracy: 0.8628\n",
            "Epoch 13/100\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.3264 - accuracy: 0.8806\n",
            "Epoch 14/100\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.2958 - accuracy: 0.8866\n",
            "Epoch 15/100\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.3067 - accuracy: 0.8793\n",
            "Epoch 16/100\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.2928 - accuracy: 0.8883\n",
            "Epoch 17/100\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.2880 - accuracy: 0.8891\n",
            "Epoch 18/100\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.2809 - accuracy: 0.8823\n",
            "Epoch 19/100\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.3040 - accuracy: 0.8898\n",
            "Epoch 20/100\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.2736 - accuracy: 0.8958\n",
            "Epoch 21/100\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.2791 - accuracy: 0.9007\n",
            "Epoch 22/100\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.2916 - accuracy: 0.8743\n",
            "Epoch 23/100\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.2755 - accuracy: 0.9018\n",
            "Epoch 24/100\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.2863 - accuracy: 0.8929\n",
            "Epoch 25/100\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.3075 - accuracy: 0.8721\n",
            "Epoch 26/100\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.2545 - accuracy: 0.9088\n",
            "Epoch 27/100\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.2968 - accuracy: 0.8867\n",
            "Epoch 28/100\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.2917 - accuracy: 0.8944\n",
            "Epoch 29/100\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.3098 - accuracy: 0.8814\n",
            "Epoch 30/100\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.2615 - accuracy: 0.9032\n",
            "Epoch 31/100\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.2716 - accuracy: 0.8940\n",
            "Epoch 32/100\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.2428 - accuracy: 0.9155\n",
            "Epoch 33/100\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.2744 - accuracy: 0.8864\n",
            "Epoch 34/100\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.2573 - accuracy: 0.9046\n",
            "Epoch 35/100\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.2622 - accuracy: 0.9055\n",
            "Epoch 36/100\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.2343 - accuracy: 0.9143\n",
            "Epoch 37/100\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.2338 - accuracy: 0.9213\n",
            "Epoch 38/100\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.2549 - accuracy: 0.9000\n",
            "Epoch 39/100\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.2483 - accuracy: 0.9114\n",
            "Epoch 40/100\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.2590 - accuracy: 0.8982\n",
            "Epoch 41/100\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.2634 - accuracy: 0.9003\n",
            "Epoch 42/100\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.2652 - accuracy: 0.8946\n",
            "Epoch 43/100\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.2411 - accuracy: 0.9108\n",
            "Epoch 44/100\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.2340 - accuracy: 0.9066\n",
            "Epoch 45/100\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.2259 - accuracy: 0.9081\n",
            "Epoch 46/100\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.2646 - accuracy: 0.8974\n",
            "Epoch 47/100\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.2273 - accuracy: 0.9134\n",
            "Epoch 48/100\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.2172 - accuracy: 0.9206\n",
            "Epoch 49/100\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.2336 - accuracy: 0.9079\n",
            "Epoch 50/100\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.2367 - accuracy: 0.9115\n",
            "Epoch 51/100\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.2146 - accuracy: 0.9270\n",
            "Epoch 52/100\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.2381 - accuracy: 0.9019\n",
            "Epoch 53/100\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.2334 - accuracy: 0.9131\n",
            "Epoch 54/100\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.2419 - accuracy: 0.9062\n",
            "Epoch 55/100\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.2211 - accuracy: 0.9144\n",
            "Epoch 56/100\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.2317 - accuracy: 0.9052\n",
            "Epoch 57/100\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.2125 - accuracy: 0.9163\n",
            "Epoch 58/100\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.2019 - accuracy: 0.9254\n",
            "Epoch 59/100\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.2279 - accuracy: 0.9093\n",
            "Epoch 60/100\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.2300 - accuracy: 0.9076\n",
            "Epoch 61/100\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.2306 - accuracy: 0.9126\n",
            "Epoch 62/100\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.2549 - accuracy: 0.9051\n",
            "Epoch 63/100\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.2123 - accuracy: 0.9079\n",
            "Epoch 64/100\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.2045 - accuracy: 0.9305\n",
            "Epoch 65/100\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.2043 - accuracy: 0.9242\n",
            "Epoch 66/100\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.2245 - accuracy: 0.9144\n",
            "Epoch 67/100\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.2331 - accuracy: 0.9062\n",
            "Epoch 68/100\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.2529 - accuracy: 0.8961\n",
            "Epoch 69/100\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.1931 - accuracy: 0.9277\n",
            "Epoch 70/100\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.2312 - accuracy: 0.9135\n",
            "Epoch 71/100\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.2393 - accuracy: 0.9009\n",
            "Epoch 72/100\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.2062 - accuracy: 0.9151\n",
            "Epoch 73/100\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.2248 - accuracy: 0.9046\n",
            "Epoch 74/100\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.2119 - accuracy: 0.9198\n",
            "Epoch 75/100\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.2136 - accuracy: 0.9266\n",
            "Epoch 76/100\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.2553 - accuracy: 0.8904\n",
            "Epoch 77/100\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.2062 - accuracy: 0.9225\n",
            "Epoch 78/100\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.2393 - accuracy: 0.8973\n",
            "Epoch 79/100\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.1861 - accuracy: 0.9222\n",
            "Epoch 80/100\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.1986 - accuracy: 0.9305\n",
            "Epoch 81/100\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.2153 - accuracy: 0.9139\n",
            "Epoch 82/100\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.1983 - accuracy: 0.9183\n",
            "Epoch 83/100\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.2240 - accuracy: 0.9024\n",
            "Epoch 84/100\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.2004 - accuracy: 0.9237\n",
            "Epoch 85/100\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.2013 - accuracy: 0.9161\n",
            "Epoch 86/100\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.2043 - accuracy: 0.9209\n",
            "Epoch 87/100\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.1982 - accuracy: 0.9212\n",
            "Epoch 88/100\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.2035 - accuracy: 0.9194\n",
            "Epoch 89/100\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.1906 - accuracy: 0.9249\n",
            "Epoch 90/100\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.2334 - accuracy: 0.9003\n",
            "Epoch 91/100\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.1814 - accuracy: 0.9339\n",
            "Epoch 92/100\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.1934 - accuracy: 0.9306\n",
            "Epoch 93/100\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.1794 - accuracy: 0.9256\n",
            "Epoch 94/100\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.1918 - accuracy: 0.9249\n",
            "Epoch 95/100\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.2035 - accuracy: 0.9192\n",
            "Epoch 96/100\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.1649 - accuracy: 0.9389\n",
            "Epoch 97/100\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.2029 - accuracy: 0.9131\n",
            "Epoch 98/100\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.1795 - accuracy: 0.9254\n",
            "Epoch 99/100\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.2012 - accuracy: 0.9091\n",
            "Epoch 100/100\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.1712 - accuracy: 0.9308\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f5f77320748>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cTiGbgXLPRug",
        "outputId": "6f6a67f4-04b7-406f-dd0f-6a3577574f7c"
      },
      "source": [
        "import tensorflow as tf\r\n",
        "from tensorflow import keras\r\n",
        "\r\n",
        "model2 = keras.models.Sequential([\r\n",
        "keras.layers.Dense(28, activation=\"relu\"),\r\n",
        "keras.layers.Dense(64, activation=\"relu\"),\r\n",
        "keras.layers.Dense(300, activation=\"relu\"),\r\n",
        "keras.layers.Dense(100, activation=\"relu\"),\r\n",
        "keras.layers.Dense(1, activation=\"sigmoid\")\r\n",
        "])\r\n",
        "\r\n",
        "model2.compile(loss=\"binary_crossentropy\",\r\n",
        "optimizer=\"nadam\",\r\n",
        "metrics=[\"accuracy\"])\r\n",
        "\r\n",
        "model2.fit(titanic_prepared, titanic_train_labels, epochs=100)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "28/28 [==============================] - 1s 2ms/step - loss: 0.6120 - accuracy: 0.6969\n",
            "Epoch 2/100\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.4311 - accuracy: 0.8096\n",
            "Epoch 3/100\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.4174 - accuracy: 0.8192\n",
            "Epoch 4/100\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.3494 - accuracy: 0.8692\n",
            "Epoch 5/100\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.3960 - accuracy: 0.8529\n",
            "Epoch 6/100\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.3956 - accuracy: 0.8347\n",
            "Epoch 7/100\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.3451 - accuracy: 0.8593\n",
            "Epoch 8/100\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.3737 - accuracy: 0.8644\n",
            "Epoch 9/100\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.3684 - accuracy: 0.8586\n",
            "Epoch 10/100\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.3563 - accuracy: 0.8578\n",
            "Epoch 11/100\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.3257 - accuracy: 0.8762\n",
            "Epoch 12/100\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.3756 - accuracy: 0.8413\n",
            "Epoch 13/100\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.3271 - accuracy: 0.8801\n",
            "Epoch 14/100\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.3222 - accuracy: 0.8870\n",
            "Epoch 15/100\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.3214 - accuracy: 0.8691\n",
            "Epoch 16/100\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.3198 - accuracy: 0.8757\n",
            "Epoch 17/100\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.3304 - accuracy: 0.8581\n",
            "Epoch 18/100\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.3188 - accuracy: 0.8739\n",
            "Epoch 19/100\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.3051 - accuracy: 0.8808\n",
            "Epoch 20/100\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.2828 - accuracy: 0.8889\n",
            "Epoch 21/100\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.2952 - accuracy: 0.8985\n",
            "Epoch 22/100\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.2452 - accuracy: 0.9099\n",
            "Epoch 23/100\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.2774 - accuracy: 0.9039\n",
            "Epoch 24/100\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.2785 - accuracy: 0.8933\n",
            "Epoch 25/100\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.2523 - accuracy: 0.9182\n",
            "Epoch 26/100\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.2690 - accuracy: 0.8918\n",
            "Epoch 27/100\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.2585 - accuracy: 0.8991\n",
            "Epoch 28/100\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.2276 - accuracy: 0.9105\n",
            "Epoch 29/100\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.2461 - accuracy: 0.9116\n",
            "Epoch 30/100\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.2568 - accuracy: 0.8889\n",
            "Epoch 31/100\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.2662 - accuracy: 0.8914\n",
            "Epoch 32/100\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.2566 - accuracy: 0.8974\n",
            "Epoch 33/100\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.2159 - accuracy: 0.9166\n",
            "Epoch 34/100\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.2607 - accuracy: 0.8920\n",
            "Epoch 35/100\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.2639 - accuracy: 0.8956\n",
            "Epoch 36/100\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.2506 - accuracy: 0.9015\n",
            "Epoch 37/100\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.2399 - accuracy: 0.9030\n",
            "Epoch 38/100\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.2585 - accuracy: 0.8926\n",
            "Epoch 39/100\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.2285 - accuracy: 0.9251\n",
            "Epoch 40/100\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.2067 - accuracy: 0.9236\n",
            "Epoch 41/100\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.2378 - accuracy: 0.9015\n",
            "Epoch 42/100\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.2400 - accuracy: 0.9007\n",
            "Epoch 43/100\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.2422 - accuracy: 0.8999\n",
            "Epoch 44/100\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.2386 - accuracy: 0.8989\n",
            "Epoch 45/100\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.2189 - accuracy: 0.9139\n",
            "Epoch 46/100\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.2275 - accuracy: 0.9116\n",
            "Epoch 47/100\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.2352 - accuracy: 0.9100\n",
            "Epoch 48/100\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.2227 - accuracy: 0.9171\n",
            "Epoch 49/100\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.2230 - accuracy: 0.9188\n",
            "Epoch 50/100\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.2301 - accuracy: 0.9074\n",
            "Epoch 51/100\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.2137 - accuracy: 0.9121\n",
            "Epoch 52/100\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.2328 - accuracy: 0.9072\n",
            "Epoch 53/100\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.2421 - accuracy: 0.9022\n",
            "Epoch 54/100\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.2400 - accuracy: 0.9030\n",
            "Epoch 55/100\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.2169 - accuracy: 0.9159\n",
            "Epoch 56/100\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.2015 - accuracy: 0.9209\n",
            "Epoch 57/100\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.2100 - accuracy: 0.9206\n",
            "Epoch 58/100\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.2117 - accuracy: 0.9195\n",
            "Epoch 59/100\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.2182 - accuracy: 0.9059\n",
            "Epoch 60/100\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.2249 - accuracy: 0.9183\n",
            "Epoch 61/100\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.2065 - accuracy: 0.9200\n",
            "Epoch 62/100\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.2181 - accuracy: 0.9047\n",
            "Epoch 63/100\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.1981 - accuracy: 0.9297\n",
            "Epoch 64/100\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.2079 - accuracy: 0.9155\n",
            "Epoch 65/100\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.2150 - accuracy: 0.9045\n",
            "Epoch 66/100\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.2053 - accuracy: 0.9240\n",
            "Epoch 67/100\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.2213 - accuracy: 0.9073\n",
            "Epoch 68/100\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.2249 - accuracy: 0.9133\n",
            "Epoch 69/100\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.2042 - accuracy: 0.9069\n",
            "Epoch 70/100\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.1940 - accuracy: 0.9182\n",
            "Epoch 71/100\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.2238 - accuracy: 0.9066\n",
            "Epoch 72/100\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.2067 - accuracy: 0.9120\n",
            "Epoch 73/100\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.1939 - accuracy: 0.9227\n",
            "Epoch 74/100\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.2029 - accuracy: 0.9158\n",
            "Epoch 75/100\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.2163 - accuracy: 0.9188\n",
            "Epoch 76/100\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.2226 - accuracy: 0.9142\n",
            "Epoch 77/100\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.2075 - accuracy: 0.9183\n",
            "Epoch 78/100\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.2048 - accuracy: 0.9142\n",
            "Epoch 79/100\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.2190 - accuracy: 0.9214\n",
            "Epoch 80/100\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.2416 - accuracy: 0.8948\n",
            "Epoch 81/100\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.2267 - accuracy: 0.9064\n",
            "Epoch 82/100\n",
            "28/28 [==============================] - 0s 3ms/step - loss: 0.2133 - accuracy: 0.9105\n",
            "Epoch 83/100\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.2039 - accuracy: 0.9183\n",
            "Epoch 84/100\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.1984 - accuracy: 0.9080\n",
            "Epoch 85/100\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.1972 - accuracy: 0.9249\n",
            "Epoch 86/100\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.2086 - accuracy: 0.9168\n",
            "Epoch 87/100\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.2001 - accuracy: 0.9111\n",
            "Epoch 88/100\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.1920 - accuracy: 0.9212\n",
            "Epoch 89/100\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.2168 - accuracy: 0.9181\n",
            "Epoch 90/100\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.1847 - accuracy: 0.9258\n",
            "Epoch 91/100\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.2009 - accuracy: 0.9152\n",
            "Epoch 92/100\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.1803 - accuracy: 0.9259\n",
            "Epoch 93/100\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.1845 - accuracy: 0.9238\n",
            "Epoch 94/100\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.1820 - accuracy: 0.9315\n",
            "Epoch 95/100\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.2071 - accuracy: 0.9007\n",
            "Epoch 96/100\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.1992 - accuracy: 0.9192\n",
            "Epoch 97/100\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.1756 - accuracy: 0.9368\n",
            "Epoch 98/100\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.1898 - accuracy: 0.9191\n",
            "Epoch 99/100\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.1695 - accuracy: 0.9251\n",
            "Epoch 100/100\n",
            "28/28 [==============================] - 0s 2ms/step - loss: 0.1960 - accuracy: 0.9180\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f5f74c1a7f0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JQWrLmFVc7Fl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "516e2a7f-acd4-4ee6-8207-4e10f5d12be3"
      },
      "source": [
        "y_pred = model.predict_classes(test)\r\n",
        "accuracy_score(titanic_test_labels, y_pred)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
            "  warnings.warn('`model.predict_classes()` is deprecated and '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9248035914702581"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "muOSkzBYPdID",
        "outputId": "fba32dee-27ad-4624-c0fe-4d102d640ea4"
      },
      "source": [
        "y_pred2 = model2.predict_classes(test)\r\n",
        "accuracy_score(titanic_test_labels, y_pred2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
            "  warnings.warn('`model.predict_classes()` is deprecated and '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9259259259259259"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jcOHssGOBsRR"
      },
      "source": [
        "get_metrics(titanic_test_labels,y_pred)\r\n",
        "res=['DNN']+get_metrics(titanic_test_labels,y_pred)\r\n",
        "Result=pd.concat([Result,pd.DataFrame([res],columns=col)])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IvrEiOlRtbgk"
      },
      "source": [
        "##K-Nearest Neighbor"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pny1Q_C5tes9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "aba43f99-b925-4a46-cf6f-7e14e3804229"
      },
      "source": [
        "from sklearn.neighbors import KNeighborsClassifier\r\n",
        "k_range=[10,20,30]\r\n",
        "weights = ['uniform', 'distance']\r\n",
        "metric = ['euclidean','manhattan']\r\n",
        "param_grid = dict(n_neighbors=k_range,weights=weights, metric=metric)\r\n",
        "\r\n",
        "knn = KNeighborsClassifier()\r\n",
        "\r\n",
        "grid_search_knn = GridSearchCV(knn, param_grid, cv=5,scoring = 'accuracy', \r\n",
        "return_train_score=True)\r\n",
        "\r\n",
        "grid_search_knn.fit(titanic_prepared, titanic_train_labels)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GridSearchCV(cv=5, error_score=nan,\n",
              "             estimator=KNeighborsClassifier(algorithm='auto', leaf_size=30,\n",
              "                                            metric='minkowski',\n",
              "                                            metric_params=None, n_jobs=None,\n",
              "                                            n_neighbors=5, p=2,\n",
              "                                            weights='uniform'),\n",
              "             iid='deprecated', n_jobs=None,\n",
              "             param_grid={'metric': ['euclidean', 'manhattan'],\n",
              "                         'n_neighbors': [6, 8, 10, 12, 14],\n",
              "                         'weights': ['uniform', 'distance']},\n",
              "             pre_dispatch='2*n_jobs', refit=True, return_train_score=True,\n",
              "             scoring='accuracy', verbose=0)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 72
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lvNMy-FUuiyF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3d4cc115-046b-4c0d-d3bf-b4d7a78e5c8a"
      },
      "source": [
        "print(grid_search_knn.best_score_)\r\n",
        "y_pred = grid_search_knn.predict(test)\r\n",
        "accuracy_score(titanic_test_labels, y_pred)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.8305630531667818\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8529741863075196"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 73
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 662
        },
        "id": "nn4WgC4YC_aT",
        "outputId": "2a83b20e-cb3e-41df-d777-e1dc72584bf2"
      },
      "source": [
        "pd.concat([pd.DataFrame(grid_search_knn.cv_results_[\"params\"]),pd.DataFrame(grid_search_knn.cv_results_[\"mean_test_score\"], columns=[\"Accuracy\"])],axis=1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>metric</th>\n",
              "      <th>n_neighbors</th>\n",
              "      <th>weights</th>\n",
              "      <th>Accuracy</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>euclidean</td>\n",
              "      <td>6</td>\n",
              "      <td>uniform</td>\n",
              "      <td>0.812592</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>euclidean</td>\n",
              "      <td>6</td>\n",
              "      <td>distance</td>\n",
              "      <td>0.791287</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>euclidean</td>\n",
              "      <td>8</td>\n",
              "      <td>uniform</td>\n",
              "      <td>0.817080</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>euclidean</td>\n",
              "      <td>8</td>\n",
              "      <td>distance</td>\n",
              "      <td>0.789021</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>euclidean</td>\n",
              "      <td>10</td>\n",
              "      <td>uniform</td>\n",
              "      <td>0.817061</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>euclidean</td>\n",
              "      <td>10</td>\n",
              "      <td>distance</td>\n",
              "      <td>0.794639</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>euclidean</td>\n",
              "      <td>12</td>\n",
              "      <td>uniform</td>\n",
              "      <td>0.819321</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>euclidean</td>\n",
              "      <td>12</td>\n",
              "      <td>distance</td>\n",
              "      <td>0.790145</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>euclidean</td>\n",
              "      <td>14</td>\n",
              "      <td>uniform</td>\n",
              "      <td>0.814839</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>euclidean</td>\n",
              "      <td>14</td>\n",
              "      <td>distance</td>\n",
              "      <td>0.791250</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>manhattan</td>\n",
              "      <td>6</td>\n",
              "      <td>uniform</td>\n",
              "      <td>0.813722</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>manhattan</td>\n",
              "      <td>6</td>\n",
              "      <td>distance</td>\n",
              "      <td>0.794639</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>manhattan</td>\n",
              "      <td>8</td>\n",
              "      <td>uniform</td>\n",
              "      <td>0.830563</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>manhattan</td>\n",
              "      <td>8</td>\n",
              "      <td>distance</td>\n",
              "      <td>0.794633</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>manhattan</td>\n",
              "      <td>10</td>\n",
              "      <td>uniform</td>\n",
              "      <td>0.818210</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>manhattan</td>\n",
              "      <td>10</td>\n",
              "      <td>distance</td>\n",
              "      <td>0.802492</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>manhattan</td>\n",
              "      <td>12</td>\n",
              "      <td>uniform</td>\n",
              "      <td>0.828316</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>manhattan</td>\n",
              "      <td>12</td>\n",
              "      <td>distance</td>\n",
              "      <td>0.799121</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>manhattan</td>\n",
              "      <td>14</td>\n",
              "      <td>uniform</td>\n",
              "      <td>0.828328</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>manhattan</td>\n",
              "      <td>14</td>\n",
              "      <td>distance</td>\n",
              "      <td>0.804727</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       metric  n_neighbors   weights  Accuracy\n",
              "0   euclidean            6   uniform  0.812592\n",
              "1   euclidean            6  distance  0.791287\n",
              "2   euclidean            8   uniform  0.817080\n",
              "3   euclidean            8  distance  0.789021\n",
              "4   euclidean           10   uniform  0.817061\n",
              "5   euclidean           10  distance  0.794639\n",
              "6   euclidean           12   uniform  0.819321\n",
              "7   euclidean           12  distance  0.790145\n",
              "8   euclidean           14   uniform  0.814839\n",
              "9   euclidean           14  distance  0.791250\n",
              "10  manhattan            6   uniform  0.813722\n",
              "11  manhattan            6  distance  0.794639\n",
              "12  manhattan            8   uniform  0.830563\n",
              "13  manhattan            8  distance  0.794633\n",
              "14  manhattan           10   uniform  0.818210\n",
              "15  manhattan           10  distance  0.802492\n",
              "16  manhattan           12   uniform  0.828316\n",
              "17  manhattan           12  distance  0.799121\n",
              "18  manhattan           14   uniform  0.828328\n",
              "19  manhattan           14  distance  0.804727"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 74
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_2tIHsajui0-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "68245f64-cba6-48ba-a8c9-82d9a299408f"
      },
      "source": [
        "get_metrics(titanic_test_labels,y_pred)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.8664, 0.8658, 0.8664, 0.8658]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GJ5FW4SwtgBP"
      },
      "source": [
        "res=['KNN']+get_metrics(titanic_test_labels,y_pred)\r\n",
        "Result=pd.concat([Result,pd.DataFrame([res],columns=col)])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "37zBDJLEumh-"
      },
      "source": [
        "##XGBoost"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BO3ThKQ0uolH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "60c3c089-d39a-4a67-ca88-4a64493c6595"
      },
      "source": [
        "from xgboost import XGBClassifier\r\n",
        "\r\n",
        "#param_grid={'min_child_weight': [1, 5, 10],}\r\n",
        "parameters = {\r\n",
        "    'learning_rate': [0.01, 0.05, 0.1]\r\n",
        "}\r\n",
        "\r\n",
        "\r\n",
        "xgb= XGBClassifier(random_state=42)\r\n",
        "grid_search_xgb = GridSearchCV(xgb, parameters, cv=5, scoring='accuracy',return_train_score=True)\r\n",
        "grid_search_xgb.fit(titanic_prepared, titanic_train_labels)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GridSearchCV(cv=5, error_score=nan,\n",
              "             estimator=XGBClassifier(base_score=0.5, booster='gbtree',\n",
              "                                     colsample_bylevel=1, colsample_bynode=1,\n",
              "                                     colsample_bytree=1, gamma=0,\n",
              "                                     learning_rate=0.1, max_delta_step=0,\n",
              "                                     max_depth=3, min_child_weight=1,\n",
              "                                     missing=None, n_estimators=100, n_jobs=1,\n",
              "                                     nthread=None, objective='binary:logistic',\n",
              "                                     random_state=42, reg_alpha=0, reg_lambda=1,\n",
              "                                     scale_pos_weight=1, seed=None, silent=None,\n",
              "                                     subsample=1, verbosity=1),\n",
              "             iid='deprecated', n_jobs=None,\n",
              "             param_grid={'learning_rate': [0.01, 0.05, 0.1]},\n",
              "             pre_dispatch='2*n_jobs', refit=True, return_train_score=True,\n",
              "             scoring='accuracy', verbose=0)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rkVOmlY7uqKo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "46d59720-c553-4f27-e817-07293d53100d"
      },
      "source": [
        "print(grid_search_xgb.best_score_)\r\n",
        "y_pred = grid_search_xgb.predict(test)\r\n",
        "accuracy_score(titanic_test_labels, y_pred)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.8395016006528154\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8888888888888888"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 137
        },
        "id": "TUW0XVfDDfDI",
        "outputId": "ccc98a14-acdf-4289-e946-9a865219d5f5"
      },
      "source": [
        "pd.concat([pd.DataFrame(grid_search_xgb.cv_results_[\"params\"]),pd.DataFrame(grid_search_xgb.cv_results_[\"mean_test_score\"], columns=[\"Accuracy\"])],axis=1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>learning_rate</th>\n",
              "      <th>Accuracy</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.01</td>\n",
              "      <td>0.831643</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.05</td>\n",
              "      <td>0.823803</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.10</td>\n",
              "      <td>0.839502</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   learning_rate  Accuracy\n",
              "0           0.01  0.831643\n",
              "1           0.05  0.823803\n",
              "2           0.10  0.839502"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wRbAIrF9uqMv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "34dac8c7-2efc-48c8-fe2f-cb0c7d677f91"
      },
      "source": [
        "get_metrics(titanic_test_labels,y_pred)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.8889, 0.8885, 0.8889, 0.8882]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t6MaULesuqPP"
      },
      "source": [
        "res=['XGB']+get_metrics(titanic_test_labels,y_pred)\r\n",
        "Result=pd.concat([Result,pd.DataFrame([res],columns=col)])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y1Oj0T_vu1Ot"
      },
      "source": [
        "##MLP"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OJqKNeJzu21u",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e0a2f2a5-5c40-4e71-d8a0-e216eda9de47"
      },
      "source": [
        "from sklearn.neural_network import MLPClassifier\r\n",
        "mlp = MLPClassifier()\r\n",
        "param_grid = {\r\n",
        "    'activation': ['tanh', 'relu'],\r\n",
        "    'solver': ['lbfgs', 'sgd', 'adam'],\r\n",
        "}\r\n",
        "grid_search_mlp = GridSearchCV(mlp, param_grid, cv=5, scoring='accuracy',return_train_score=True)\r\n",
        "grid_search_mlp.fit(titanic_prepared, titanic_train_labels)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GridSearchCV(cv=5, error_score=nan,\n",
              "             estimator=MLPClassifier(activation='relu', alpha=0.0001,\n",
              "                                     batch_size='auto', beta_1=0.9,\n",
              "                                     beta_2=0.999, early_stopping=False,\n",
              "                                     epsilon=1e-08, hidden_layer_sizes=(100,),\n",
              "                                     learning_rate='constant',\n",
              "                                     learning_rate_init=0.001, max_fun=15000,\n",
              "                                     max_iter=200, momentum=0.9,\n",
              "                                     n_iter_no_change=10,\n",
              "                                     nesterovs_momentum=True, power_t=0.5,\n",
              "                                     random_state=None, shuffle=True,\n",
              "                                     solver='adam', tol=0.0001,\n",
              "                                     validation_fraction=0.1, verbose=False,\n",
              "                                     warm_start=False),\n",
              "             iid='deprecated', n_jobs=None,\n",
              "             param_grid={'activation': ['tanh', 'relu'],\n",
              "                         'solver': ['lbfgs', 'sgd', 'adam']},\n",
              "             pre_dispatch='2*n_jobs', refit=True, return_train_score=True,\n",
              "             scoring='accuracy', verbose=0)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r6m3VpLzu4w6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4f150567-bc93-472d-809e-e8fb6e5174f5"
      },
      "source": [
        "print(grid_search_mlp.best_score_)\r\n",
        "y_pred = grid_search_mlp.predict(test)\r\n",
        "accuracy_score(titanic_test_labels, y_pred)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.833927562613772\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8507295173961841"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 227
        },
        "id": "dE1nTi31FEDl",
        "outputId": "76fde691-0c28-4be9-e80c-a2d048ecc00e"
      },
      "source": [
        "pd.concat([pd.DataFrame(grid_search_mlp.cv_results_[\"params\"]),pd.DataFrame(grid_search_mlp.cv_results_[\"mean_test_score\"], columns=[\"Accuracy\"])],axis=1)\r\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>activation</th>\n",
              "      <th>solver</th>\n",
              "      <th>Accuracy</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>tanh</td>\n",
              "      <td>lbfgs</td>\n",
              "      <td>0.748616</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>tanh</td>\n",
              "      <td>sgd</td>\n",
              "      <td>0.815919</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>tanh</td>\n",
              "      <td>adam</td>\n",
              "      <td>0.833928</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>relu</td>\n",
              "      <td>lbfgs</td>\n",
              "      <td>0.757642</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>relu</td>\n",
              "      <td>sgd</td>\n",
              "      <td>0.808066</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>relu</td>\n",
              "      <td>adam</td>\n",
              "      <td>0.826062</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  activation solver  Accuracy\n",
              "0       tanh  lbfgs  0.748616\n",
              "1       tanh    sgd  0.815919\n",
              "2       tanh   adam  0.833928\n",
              "3       relu  lbfgs  0.757642\n",
              "4       relu    sgd  0.808066\n",
              "5       relu   adam  0.826062"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 67
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TtV_GFtXu4z4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e89f415a-fecc-4afd-9b28-877ce0fa38dc"
      },
      "source": [
        "get_metrics(titanic_test_labels,y_pred)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.8507, 0.8508, 0.8507, 0.8484]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 68
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "46lawcWzu43I"
      },
      "source": [
        "res=['MLP']+get_metrics(titanic_test_labels,y_pred)\r\n",
        "Result=pd.concat([Result,pd.DataFrame([res],columns=col)])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3KBLVG9Nu7So"
      },
      "source": [
        "##RESULT"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "myqlUKh4u8io",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 257
        },
        "outputId": "d3130786-1ac2-4cff-e0f8-77a7b9848ddb"
      },
      "source": [
        "display(Result)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Model</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>F1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>SGD</td>\n",
              "      <td>0.8182</td>\n",
              "      <td>0.8208</td>\n",
              "      <td>0.8182</td>\n",
              "      <td>0.8191</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>RF</td>\n",
              "      <td>0.9742</td>\n",
              "      <td>0.9742</td>\n",
              "      <td>0.9742</td>\n",
              "      <td>0.9741</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>SVM</td>\n",
              "      <td>0.8474</td>\n",
              "      <td>0.8471</td>\n",
              "      <td>0.8474</td>\n",
              "      <td>0.8452</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>DNN</td>\n",
              "      <td>0.9248</td>\n",
              "      <td>0.9259</td>\n",
              "      <td>0.9248</td>\n",
              "      <td>0.9240</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>KNN</td>\n",
              "      <td>0.8664</td>\n",
              "      <td>0.8658</td>\n",
              "      <td>0.8664</td>\n",
              "      <td>0.8658</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>XGB</td>\n",
              "      <td>0.8889</td>\n",
              "      <td>0.8885</td>\n",
              "      <td>0.8889</td>\n",
              "      <td>0.8882</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>MLP</td>\n",
              "      <td>0.8507</td>\n",
              "      <td>0.8508</td>\n",
              "      <td>0.8507</td>\n",
              "      <td>0.8484</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  Model  Accuracy  Precision  Recall      F1\n",
              "0   SGD    0.8182     0.8208  0.8182  0.8191\n",
              "0    RF    0.9742     0.9742  0.9742  0.9741\n",
              "0   SVM    0.8474     0.8471  0.8474  0.8452\n",
              "0   DNN    0.9248     0.9259  0.9248  0.9240\n",
              "0   KNN    0.8664     0.8658  0.8664  0.8658\n",
              "0   XGB    0.8889     0.8885  0.8889  0.8882\n",
              "0   MLP    0.8507     0.8508  0.8507  0.8484"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    }
  ]
}